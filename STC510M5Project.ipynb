{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Parse, clean, and organize the Jeopardy! question data file to train a Naive Bayesian classifier.\n",
        "\n",
        "2. Pass the Text Analysis Basics quiz with a score of 85% or better.\n",
        "\n",
        "Just as we have built a classifier above, your aim here is to make sense of the data presented, and create a binary classifier (\"high value\" and \"low value,\" based on the points available for each) for questions. Despite the large number of questions, this is an extraordinarily difficult classification problem.\n",
        "\n",
        "Consider it as a human coder: how often could you tell those questions that are \"easy\" versus \"hard\"? The degree to which you are successful in this is largely based on your own contextual knowledge--indeed, you might be tempted to classify questions you know the answer to as \"easy\" and those you do not as \"hard.\" The computer doesn't know the answers to any of these.\n",
        "\n",
        "For that reason, do not be discouraged if your classifier does not perform well. This constitutes an especially difficult problem for a simple classifier to solve."
      ],
      "metadata": {
        "id": "Wm5UsBQdppuf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6HTcTnIggq4S"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jeopdata = pd.read_json('jeopardy.json')\n",
        "print(jeopdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brrtT6pFqVyk",
        "outputId": "0db52482-cac0-44e4-8cec-e737bbff541f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               category    air_date  \\\n",
            "0                               HISTORY  2004-12-31   \n",
            "1       ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
            "2           EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
            "3                      THE COMPANY LINE  2004-12-31   \n",
            "4                   EPITAPHS & TRIBUTES  2004-12-31   \n",
            "...                                 ...         ...   \n",
            "216925                   RIDDLE ME THIS  2006-05-11   \n",
            "216926                        \"T\" BIRDS  2006-05-11   \n",
            "216927           AUTHORS IN THEIR YOUTH  2006-05-11   \n",
            "216928                       QUOTATIONS  2006-05-11   \n",
            "216929                   HISTORIC NAMES  2006-05-11   \n",
            "\n",
            "                                                 question  value  \\\n",
            "0       'For the last 8 years of his life, Galileo was...   $200   \n",
            "1       'No. 2: 1912 Olympian; football star at Carlis...   $200   \n",
            "2       'The city of Yuma in this state has a record a...   $200   \n",
            "3       'In 1963, live on \"The Art Linkletter Show\", t...   $200   \n",
            "4       'Signer of the Dec. of Indep., framer of the C...   $200   \n",
            "...                                                   ...    ...   \n",
            "216925  'This Puccini opera turns on the solution to 3...  $2000   \n",
            "216926  'In North America this term is properly applie...  $2000   \n",
            "216927  'In Penny Lane, where this \"Hellraiser\" grew u...  $2000   \n",
            "216928  'From Ft. Sill, Okla. he made the plea, Arizon...  $2000   \n",
            "216929  'A silent movie title includes the last name o...   None   \n",
            "\n",
            "                                answer             round  show_number  \n",
            "0                           Copernicus         Jeopardy!         4680  \n",
            "1                           Jim Thorpe         Jeopardy!         4680  \n",
            "2                              Arizona         Jeopardy!         4680  \n",
            "3                          McDonald\\'s         Jeopardy!         4680  \n",
            "4                           John Adams         Jeopardy!         4680  \n",
            "...                                ...               ...          ...  \n",
            "216925                        Turandot  Double Jeopardy!         4999  \n",
            "216926                      a titmouse  Double Jeopardy!         4999  \n",
            "216927                    Clive Barker  Double Jeopardy!         4999  \n",
            "216928                        Geronimo  Double Jeopardy!         4999  \n",
            "216929  Grigori Alexandrovich Potemkin   Final Jeopardy!         4999  \n",
            "\n",
            "[216930 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing special characters from values and changing dtype to float\n",
        "jeopdata['value'] = jeopdata['value'].str.replace('$', '').str.replace(',', '').astype(float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LknmnV2AT04",
        "outputId": "42fbbc39-a7cc-47b7-c408-ec783044e502"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-94d5ea014522>:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  jeopdata['value'] = jeopdata['value'].str.replace('$', '').str.replace(',', '').astype(float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the logistic regression classifier\n",
        "logistic_reg = LogisticRegression(max_iter=1000)"
      ],
      "metadata": {
        "id": "1HhAYPJS7Atj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the TFIDF Vectorizer to get rid of stop words\n",
        "stop = TfidfVectorizer(stop_words='english')"
      ],
      "metadata": {
        "id": "5GTNl_Vy7JSO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a threshold\n",
        "threshold= 1000"
      ],
      "metadata": {
        "id": "Vxwv1FM18-_w"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning label based on the threshold\n",
        "HiLo = jeopdata['value'].apply(lambda x: 'high value' if x >= threshold else 'low value')"
      ],
      "metadata": {
        "id": "zdHEcuzu84o3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning X & y for classifer\n",
        "X = jeopdata['question']\n",
        "y = HiLo\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKQv4lJxZL5n",
        "outputId": "5fdec7ce-3e7c-486c-f194-ddf6c6ed1b05"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         'For the last 8 years of his life, Galileo was...\n",
            "1         'No. 2: 1912 Olympian; football star at Carlis...\n",
            "2         'The city of Yuma in this state has a record a...\n",
            "3         'In 1963, live on \"The Art Linkletter Show\", t...\n",
            "4         'Signer of the Dec. of Indep., framer of the C...\n",
            "                                ...                        \n",
            "216925    'This Puccini opera turns on the solution to 3...\n",
            "216926    'In North America this term is properly applie...\n",
            "216927    'In Penny Lane, where this \"Hellraiser\" grew u...\n",
            "216928    'From Ft. Sill, Okla. he made the plea, Arizon...\n",
            "216929    'A silent movie title includes the last name o...\n",
            "Name: question, Length: 216930, dtype: object\n",
            "0          low value\n",
            "1          low value\n",
            "2          low value\n",
            "3          low value\n",
            "4          low value\n",
            "             ...    \n",
            "216925    high value\n",
            "216926    high value\n",
            "216927    high value\n",
            "216928    high value\n",
            "216929     low value\n",
            "Name: value, Length: 216930, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gfY9DTvuvYsF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf = stop.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "b3Fuqvwv7o5u"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tfidf = stop.transform(X_test)"
      ],
      "metadata": {
        "id": "P3YcJq-d9InG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the classifier\n",
        "logistic_reg.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "TDkE5AFj7Eho",
        "outputId": "21292825-a5c2-4d74-cecd-effd1edc6f36"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on the test set\n",
        "y_pred = logistic_reg.predict(X_test_tfidf)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZItnY_89AVQ",
        "outputId": "0f1e58cb-7da5-4157-e874-f798e33cbf3b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['low value' 'low value' 'low value' ... 'low value' 'low value'\n",
            " 'low value']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the classifier\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVMt_46q-Nih",
        "outputId": "591dd366-bcba-4753-c371-f1b821f3f8d1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.719679159175771"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}